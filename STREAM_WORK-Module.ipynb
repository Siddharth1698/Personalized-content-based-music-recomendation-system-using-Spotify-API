{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import Normalizer, StandardScaler\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "kafka_topic_name = \"songTopic\"\n",
    "kafka_bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Spotify Streaming Reccomendation System\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Construct a streaming DataFrame that reads from test-topic\n",
    "songs_df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "        .option(\"subscribe\", kafka_topic_name) \\\n",
    "        .option(\"startingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "\n",
    "songs_df1 = songs_df.selectExpr(\"CAST(value AS STRING)\", \"timestamp\")\n",
    "\n",
    "\n",
    "songs_schema_string = \"order_id INT,id STRING, name STRING,popularity INT, duration_ms DOUBLE, explicit INT, \" \\\n",
    "                           + \"artists STRING, id_artists STRING, release_date STRING, \" \\\n",
    "                           + \"danceability DOUBLE,\" \\\n",
    "                           + \"energy DOUBLE, key INT, loudness DOUBLE, \" \\\n",
    "                           + \"mode INT,\" \\\n",
    "                           + \"speechiness DOUBLE,\" \\\n",
    "                           + \"acousticness DOUBLE, instrumentalness DOUBLE, liveness DOUBLE, \" \\\n",
    "                           + \"valence DOUBLE, tempo DOUBLE, time_signature DOUBLE\"\n",
    "\n",
    "\n",
    "\n",
    "songs_df2 = songs_df1 \\\n",
    "        .select(from_csv(col(\"value\"), songs_schema_string) \\\n",
    "                .alias(\"song\"), \"timestamp\")\n",
    "\n",
    "\n",
    "songs_df3 = songs_df2.select(\"song.*\", \"timestamp\")\n",
    "\n",
    "def simple():    \n",
    "    songs_df3.createOrReplaceTempView(\"song_find\");\n",
    "    song_find_text = spark.sql(\"SELECT name, artists FROM song_find\")\n",
    "    songs_agg_write_stream = song_find_text \\\n",
    "            .writeStream \\\n",
    "            .trigger(processingTime='5 seconds') \\\n",
    "            .outputMode(\"update\") \\\n",
    "            .option(\"truncate\", \"false\") \\\n",
    "            .format(\"console\") \\\n",
    "            .start()\n",
    "\n",
    "    songs_agg_write_stream.awaitTermination()\n",
    "\n",
    "    print(\"Songs Streaming...\")\n",
    "    \n",
    "def csv_output():    \n",
    "    song_find_text = spark.sql(\"SELECT name, artists FROM song_find\")\n",
    "    songs_agg_write_stream = song_find_text \\\n",
    "            .writeStream \\\n",
    "            .trigger(processingTime='5 seconds') \\\n",
    "            .outputMode(\"append\") \\\n",
    "            .option(\"truncate\", \"false\") \\\n",
    "            .option(\"path\",'answ') \\\n",
    "            .option(\"checkpointLocation\", \"checkpoint_path\") \\\n",
    "            .format(\"csv\") \\\n",
    "            .start()\n",
    "\n",
    "    songs_agg_write_stream.awaitTermination()\n",
    "\n",
    "    print(\"Songs Streaming...\")\n",
    "    \n",
    "songs_df3.createOrReplaceTempView(\"song_find\");\n",
    "song_find_text = spark.sql(\"SELECT * FROM song_find\")\n",
    "songs_agg_write_stream = song_find_text \\\n",
    "        .writeStream \\\n",
    "        .trigger(processingTime='5 seconds') \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .option(\"truncate\", \"false\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .queryName(\"testedTable5\") \\\n",
    "        .start()\n",
    "\n",
    "songs_agg_write_stream.awaitTermination(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 tracks\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from spotify_api import getSong\n",
    "song_data = getSong.passs()\n",
    "#song_data.rename(columns={'duration_s': 'duration_ms' }, inplace=True)\n",
    "song_data = song_data.drop(['id', 'added_at', 'time_signature','duration_s'], axis='columns')\n",
    "rand_n = random. randint(0,len(song_data)-1)\n",
    "add_df = song_data.head(rand_n)[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>energy</th>\n",
       "      <th>tempo</th>\n",
       "      <th>loudness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAST MAGAN lo-fi</td>\n",
       "      <td>Aadesh Goud</td>\n",
       "      <td>58</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>1</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.429</td>\n",
       "      <td>102.712</td>\n",
       "      <td>-11.847</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name      artists  popularity  acousticness  speechiness key  \\\n",
       "2  MAST MAGAN lo-fi  Aadesh Goud          58         0.827       0.0542   1   \n",
       "\n",
       "   liveness  instrumentalness  energy    tempo  loudness  danceability  \\\n",
       "2     0.424          0.000215   0.429  102.712   -11.847         0.384   \n",
       "\n",
       "   valence  \n",
       "2    0.302  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 317/317 [00:00<00:00, 13780.75it/s]\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM testedTable5\")\n",
    "\n",
    "df = df.sort(df.release_date.desc())\n",
    "\n",
    "df = df.drop('order_id',\n",
    " 'id',\n",
    " 'explicit',\n",
    "  'mode',\n",
    " 'release_date',\n",
    " 'id_artists',\n",
    " 'time_signature',\n",
    " 'duration_ms',\n",
    " 'timestamp')\n",
    "\n",
    "df_sp = spark.createDataFrame(add_df)\n",
    "df = df.union(df_sp)\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler=VectorAssembler(inputCols=[\n",
    " 'danceability',\n",
    " 'energy',\n",
    " 'loudness',\n",
    " 'speechiness',\n",
    " 'acousticness',\n",
    " 'instrumentalness',\n",
    " 'liveness',\n",
    " 'valence',\n",
    " 'tempo'], outputCol='features')\n",
    "assembled_data=assembler.setHandleInvalid(\"skip\").transform(df)\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "scale=StandardScaler(inputCol='features',outputCol='standardized')\n",
    "data_scale=scale.fit(assembled_data)\n",
    "df=data_scale.transform(assembled_data)\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "silhouette_score=[]\n",
    "evaluator = ClusteringEvaluator(predictionCol='prediction', featuresCol='standardized', \\\n",
    "                                metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "\n",
    "\n",
    "KMeans_algo=KMeans(featuresCol='standardized', k=4)\n",
    "    \n",
    "KMeans_fit=KMeans_algo.fit(df)\n",
    "    \n",
    "output_df =KMeans_fit.transform(df)\n",
    "  \n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class SpotifyRecommender():\n",
    "    def __init__(self, rec_data):\n",
    "        #our class should understand which data to work with\n",
    "        self.rec_data_ = rec_data\n",
    "    \n",
    "    #function which returns recommendations, we can also choose the amount of songs to be recommended\n",
    "    def spotify_recommendations(self, song_name, amount=1):\n",
    "        distances = []\n",
    "        #choosing the data for our song\n",
    "        song = self.rec_data_[(self.rec_data_.name.str.lower() == song_name.lower())].head(1).values[0]\n",
    "        #dropping the data with our song\n",
    "        res_data = self.rec_data_[self.rec_data_.name.str.lower() != song_name.lower()]\n",
    "        for r_song in tqdm(res_data.values):\n",
    "            dist = 0\n",
    "            for col in np.arange(len(res_data.columns)):\n",
    "                #indeces of non-numerical columns\n",
    "                if not col in [0,1]:\n",
    "                    #calculating the manhettan distances for each numerical feature\n",
    "                    dist = dist + np.absolute(float(song[col]) - float(r_song[col]))\n",
    "            distances.append(dist)\n",
    "        res_data['distance'] = distances\n",
    "        #sorting our data to be ascending by 'distance' feature\n",
    "        res_data = res_data.sort_values('distance')\n",
    "        columns = ['name', 'artists', 'acousticness', 'liveness', 'instrumentalness', 'energy', 'danceability', 'valence']\n",
    "        return res_data[columns][:amount]\n",
    "    \n",
    "    \n",
    "datad = output_df.select('name',\n",
    " 'artists',\n",
    " 'danceability',\n",
    " 'energy',\n",
    " 'key',\n",
    " 'loudness',\n",
    " 'speechiness',\n",
    " 'acousticness',\n",
    " 'instrumentalness',\n",
    " 'liveness',\n",
    " 'valence',\n",
    " 'tempo',\n",
    " 'prediction')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datf = datad.toPandas()\n",
    "datf.drop(datf[datf['artists'] == '0'].index, inplace = True)\n",
    "datf.drop_duplicates(inplace=True)\n",
    "datf.drop(datf[datf['danceability'] == 0.0000].index, inplace = True)\n",
    "datf.drop(datf[datf['liveness'] == 0.000].index, inplace = True)\n",
    "datf.drop(datf[datf['instrumentalness'] == 0.000000].index, inplace = True)\n",
    "datf.drop(datf[datf['energy'] == 0.0000].index, inplace = True)\n",
    "datf.drop(datf[datf['danceability'] == 0.000].index, inplace = True)\n",
    "datf.drop(datf[datf['valence'] == 0.000].index, inplace = True)\n",
    "\n",
    "value_pred = datf.iloc[-1:]['prediction']\n",
    "#datf = datf[datf['prediction'] == list(value_pred)[0]]\n",
    "\n",
    "recommender = SpotifyRecommender(datf)\n",
    "x = add_df['name'].tolist()[0]\n",
    "\n",
    "rec_song = recommender.spotify_recommendations(x, 6)\n",
    "\n",
    "v = add_df[['name', 'artists',  'acousticness', 'liveness', 'instrumentalness', 'energy', \n",
    "       'danceability', 'valence']]\n",
    "\n",
    "rec_song = pd.concat([rec_song, v])\n",
    "rec_song.to_csv('rec_song.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
